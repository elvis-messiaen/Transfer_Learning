{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## L'équipe en médecine pour la détection des pneumonies\n",
    "\n",
    "##### L'analyse des radiographies thoraciques permet de détecter les cas de pneumonie.\n",
    "\n",
    "##### Automatiser cette action et améliorer la prédiction des cas est indispensable.\n",
    "\n",
    "##### Un POC (Proof of Concept) sera réalisé avec :\n",
    "- **Utilisation du Transfert Learning** pour les prédictions.\n",
    "- **Application de CNN** sur les modèles de Transfert Learning pour améliorer les performances et réduire les coûts.\n",
    "- **Déploiement sur GitHub** pour assurer la versioning et l'accessibilité du projet.\n",
    "- **Intégration de MLOps** pour la gestion du cycle de vie du modèle.\n",
    "- **Mise en place d'un historique** pour suivre les tests effectués.\n",
    "- **Préparation rigoureuse du dataset** pour garantir la pertinence des données utilisées.\n",
    "- **Visualisation des résultats via des graphiques** pour mettre en évidence les performances du modèle.\n",
    "- **Ajout d'un `.gitignore`** pour éviter d'inclure les bibliothèques et frameworks inutiles.\n",
    "- **Rédaction d'un README.md** pour détailler le projet et son implémentation.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Lecture du rapport de 2024\n",
    "\n",
    "- Référence : [MDPI - Rapport 2024](https://www.mdpi.com/2306-5354/11/4/)\n",
    "- Le rapport souligne l'importance d'utiliser des modèles pré-entraînés plutôt que d'entraîner ses propres réseaux CNN.\n",
    "- Bien que CNN affiche un bon taux de réussite, l'adoption de modèles pré-entraînés optimise le temps et les ressources.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Compétences sur le Transfert Learning\n",
    "\n",
    "#### Pourquoi utiliser le Transfert Learning ?\n",
    "- **Optimisation du travail sur les réseaux neuronaux**.\n",
    "- **Réduction de la quantité de données à stocker**.\n",
    "- **Prévention du sur-apprentissage** pour améliorer la généralisation.\n",
    "- **Gain de temps et réduction des coûts en ressources mémoire et calcul**.\n",
    "- **Modèles existants performants, adaptés aux besoins spécifiques du projet**.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Choix du modèle de Transfert Learning\n",
    "\n",
    "#### Critères de sélection :\n",
    "- **Accuracy obtenue**.\n",
    "- **Loss mesuré**.\n",
    "- **Temps d'exécution**.\n",
    "- **Coût en termes de données**.\n",
    "- **Tests de performance** pour identifier le modèle le plus pertinent.\n",
    "- **Mise en place d'un historique** pour documenter les performances.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparaison des modèles testés\n",
    "\n",
    "| Modèle     | Accuracy | Loss   |\n",
    "|------------|----------|--------|\n",
    "| **VGG16**  | 91.18%   | 0.41   |\n",
    "| **ResNet50** | 77,00%   | 0,32   |\n",
    "| **Xception** | 81.57%   | 0.0595 |\n",
    "\n",
    "#### Justification du choix :\n",
    "- **VGG16 affiche la meilleure accuracy**.\n",
    "- **Loss faible** indiquant une bonne fiabilité du modèle.\n",
    "- **Temps par époque** : 50 secondes.\n",
    "- **MLflow** documente les tests et valide le choix du modèle.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pourquoi Xception est le Meilleur Choix ?\n",
    "\n",
    "### 1. Comparaison des architectures\n",
    "\n",
    "| Modèle | Profondeur | Paramètres | Points Forts | Points Faibles |\n",
    "|--------|------------|------------|--------------|----------------|\n",
    "| VGG16 | 16 | 138M | Architecture claire | Très lourd en calcul |\n",
    "| ResNet50 | 50 | 25.6M | Meilleure convergence | Complexe à optimiser |\n",
    "| Xception | 71 | 22.9M | Convolutions séparables | Nécessite plus de données |\n",
    "\n",
    "### 2. Avantages techniques\n",
    "- **Efficacité computationnelle** grâce aux convolutions séparables.\n",
    "- **Moins de paramètres**, donc entraînement plus rapide.\n",
    "- **Adapté aux images médicales** pour une classification fine.\n",
    "\n",
    "### 3. Performance sur notre dataset\n",
    "- **Accuracy** : 91.18%\n",
    "- **Loss** : 0.041\n",
    "- **Temps d'entraînement par époque** : 50 secondes\n",
    "\n",
    "### 4. Validation et tests\n",
    "- **Robustesse face aux variations de qualité d’image**.\n",
    "- **Cohérence des prédictions** sur différents cas cliniques.\n",
    "- **Optimisation des hyperparamètres et de l’architecture**.\n",
    "\n",
    "### 5. Conclusion et évolutions futures\n",
    "- **Fine-tuning continu** pour améliorer la performance.\n",
    "- **Intégration de nouvelles données pour enrichir le modèle**.\n",
    "- **Déploiement et optimisation du temps de calcul**.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
